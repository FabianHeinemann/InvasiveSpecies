{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import data, io, filters, transform\n",
    "from skimage.transform import resize\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Load functions to read images\n",
    "from keras.preprocessing import image as image_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statement of mission\n",
    "\n",
    "In this notebook a simple (default) network is trained on images of size (150, 150).\n",
    "The training data is generated before training and written to disk.\n",
    "The idea behind this is to be able to have a look at images that are not classified correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define parameters:\n",
    "\n",
    "# Parameters for the transformations in Data Augmentation\n",
    "idg_width_shift_range = 0.2\n",
    "idg_height_shift_range = 0.2\n",
    "idg_shear_range = 0.2\n",
    "idg_zoom_range = 0.2\n",
    "idg_horflip = True\n",
    "\n",
    "# Parameters for data output (image size, number of trafos)\n",
    "target_size = (150, 150)\n",
    "num_versions = 10\n",
    "input_shape = target_size + (3, )\n",
    "\n",
    "# Fraction of data for validation\n",
    "val_fraction = 0.2\n",
    "\n",
    "# Parameters for training\n",
    "batch_size = 10 \n",
    "file_weights = \"weights_examplePicsNetwork.h5\"\n",
    "\n",
    "# threshold for classicfication\n",
    "threshold_class = 0.5"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": null,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read labels of the training data\n",
    "train_labels = pd.read_csv(\"data/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 3,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# Make two image augmentation data generators. One without transformation (for validation data)\n",
=======
    "# Make to image augmentation data generators. One without transformation (for validation data)\n",
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
    "no_transform_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "image_prep_gen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   width_shift_range = idg_width_shift_range,\n",
    "                                   height_shift_range = idg_height_shift_range,\n",
    "                                   shear_range = idg_shear_range,\n",
    "                                   zoom_range = idg_zoom_range,\n",
    "                                   horizontal_flip = idg_horflip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder structure\n",
    "\n",
    "The training and validation data is written to folders train\\_small and val\\_small in order to\n",
    "keep it separate from other network runs."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 10,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# I am getting weird error messages sometimes when running this cell. Don't know why;\n",
    "# I suspect it is probably a bad idea running file io in loops.\n",
    "\n",
    "dirlist = [\"data/train_small/0/\",\n",
    "           \"data/train_small/1/\",\n",
    "           \"data/val_small/0/\",\n",
    "           \"data/val_small/1/\",\n",
    "           \"data/test_0/\",\n",
    "           \"data/test_1/\"]\n",
    "\n",
    "for element in dirlist:\n",
    "    if os.path.exists(element):\n",
    "        shutil.rmtree(element)\n",
    "\n",
    "for element in dirlist:\n",
    "    os.makedirs(element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate training- and validation data\n",
    "\n",
    "The training data consists of a subset of the original training images augmented by a number of\n",
    "transformed images (set by num\\_versions). The validation data is not transformed; the intent is\n",
    "to get a glimpse of the pictures that won't get classified correctly."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 11,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for file_counter in range(0, train_labels.shape[0]):\n",
    "    file_id = str(train_labels[\"name\"][file_counter])\n",
    "    \n",
    "    # Load image, make it an array so the flow()-method can work with it.\n",
<<<<<<< HEAD
    "    img = image_utils.load_img(\"data/train/\" + file_id + \".jpg\", target_size = target_size)\n",
=======
    "    img = image_utils.load_img(\"data_save/train/\" + file_id + \".jpg\", target_size = target_size)\n",
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
    "    img = image_utils.img_to_array(img)\n",
    "    img = img.reshape((1, ) + img.shape)\n",
    "    \n",
    "    # Make sure the file names start with the number of the source file and the label\n",
    "    file_prefix = file_id.rjust(4, \"0\") + \"_\" + str(train_labels[\"invasive\"][file_counter]) + \"_\"\n",
    "    \n",
    "    if np.random.rand() < val_fraction:\n",
    "        save_to_dir = \"data/val_small/\" + str(train_labels[\"invasive\"][file_counter]) + \"/\"\n",
    "        for batch in no_transform_datagen.flow(x = img, batch_size = 1, save_to_dir = save_to_dir,\n",
    "                                            save_prefix = file_prefix, save_format = \"jpg\"):\n",
    "            break # Stop the image generation after the first image\n",
    "    else:\n",
    "        save_to_dir = \"data/train_small/\" + str(train_labels[\"invasive\"][file_counter]) + \"/\"\n",
    "        counter = 0\n",
    "        for batch in image_prep_gen.flow(x = img, batch_size = 1, save_to_dir = save_to_dir,\n",
    "                                            save_prefix = file_prefix, save_format = \"jpg\"):\n",
    "            counter += 1\n",
    "            if counter > (num_versions - 1):\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 12,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Found 17945 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
=======
      "Found 18621 images belonging to 2 classes.\n",
      "Found 432 images belonging to 2 classes.\n"
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
     ]
    }
   ],
   "source": [
    "# Since the image generation has been outsourced to the previous section, I can now\n",
    "# create data generators without transformations\n",
    "# However, I am still not sure what batch size is in the context of an image generator\n",
    "# Ok, seems to be the number of pics looked at before a gradient computations or something.\n",
    "\n",
    "train_generator = no_transform_datagen.flow_from_directory(\"data/train_small\", target_size = target_size,\n",
    "                                                     batch_size = batch_size, class_mode = \"binary\")\n",
    "\n",
    "val_generator = no_transform_datagen.flow_from_directory(\"data/val_small\", target_size = target_size,\n",
    "                                                   batch_size = batch_size, class_mode = \"binary\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 13,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Above are the conv layers, below the dense layers\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the weights are already available, load them instead of training the network anew."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 14,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Next on is model fitting. Check if the weights are already saved, in\n",
    "# this case no fitting is necessary\n",
    "if os.path.exists(file_weights):\n",
    "    model.load_weights(file_weights)\n",
    "else:\n",
    "    model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=18000 // batch_size,\n",
    "            epochs=5,\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=4000 // batch_size)\n",
    "    model.save_weights(file_weights)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 15,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/test_1/test'"
      ]
     },
<<<<<<< HEAD
     "execution_count": 11,
=======
     "execution_count": 15,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy images from val/0 and val/1 into test_0/test and test_1/test for the generators\n",
    "# (Hmm, the interface makes standard stuff easy, but to me it seems it is just a tad to inflexible)\n",
    "\n",
    "shutil.copytree(src = \"data/val_small/0\", dst = \"data/test_0/test\")\n",
    "shutil.copytree(src = \"data/val_small/1\", dst = \"data/test_1/test\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 16,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Found 200 images belonging to 1 classes.\n",
      "Found 300 images belonging to 1 classes.\n"
=======
      "Found 173 images belonging to 1 classes.\n",
      "Found 259 images belonging to 1 classes.\n"
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
     ]
    }
   ],
   "source": [
    "# Make two generators, one for each folder in val_small in order to see when\n",
    "# the model fails in each class\n",
    "\n",
    "val_0_generator = no_transform_datagen.flow_from_directory(directory = \"data/test_0/\",\n",
    "                                                      target_size = target_size,\n",
    "                                                      batch_size = 1,\n",
    "                                                      class_mode = None,\n",
    "                                                      shuffle = False)\n",
    "val_1_generator = no_transform_datagen.flow_from_directory(directory = \"data/test_1/\",\n",
    "                                                      target_size = target_size,\n",
    "                                                      batch_size = 1,\n",
    "                                                      class_mode = None,\n",
    "                                                      shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 17,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "297/300 [============================>.] - ETA: 0s"
=======
      "173/173 [==============================] - 3s     \n",
      "256/259 [============================>.] - ETA: 0s"
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
     ]
    }
   ],
   "source": [
    "val_0_predictions = model.predict_generator(val_0_generator, val_0_generator.n, verbose = 1)\n",
    "\n",
    "val_1_predictions = model.predict_generator(val_1_generator, val_1_generator.n, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 18,
>>>>>>> 0032669b3dfb9cb1faf745aa044c1a51ef4a6ba2
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"data/test_0/test/correct\"):\n",
    "    os.makedirs(\"data/test_0/test/correct\")\n",
    "if not os.path.exists(\"data/test_0/test/incorrect\"):\n",
    "    os.makedirs(\"data/test_0/test/incorrect\")\n",
    "\n",
    "if not os.path.exists(\"data/test_1/test/correct\"):\n",
    "    os.makedirs(\"data/test_1/test/correct\")\n",
    "if not os.path.exists(\"data/test_1/test/incorrect\"):\n",
    "    os.makedirs(\"data/test_1/test/incorrect\")\n",
    "    \n",
    "    \n",
    "# I know there must be a way to iterate over two lists at the same time, but I don't know how\n",
    "# it can be done\n",
    "counter = 0\n",
    "for prediction in val_0_predictions:\n",
    "    filename = val_0_generator.filenames[counter][5:]\n",
    "    \n",
    "    if prediction > threshold_class:\n",
    "        shutil.move(\"data/test_0/test/\" + filename, \"data/test_0/test/incorrect/\" + filename)\n",
    "    else:\n",
    "        shutil.move(\"data/test_0/test/\" + filename, \"data/test_0/test/correct/\" + filename)\n",
    "        \n",
    "    counter += 1\n",
    "\n",
    "counter = 0\n",
    "for prediction in val_1_predictions:\n",
    "    filename = val_1_generator.filenames[counter][5:]\n",
    "    \n",
    "    if prediction <= threshold_class:\n",
    "        shutil.move(\"data/test_1/test/\" + filename, \"data/test_1/test/incorrect/\" + filename)\n",
    "    else:\n",
    "        shutil.move(\"data/test_1/test/\" + filename, \"data/test_1/test/correct/\" + filename)\n",
    "        \n",
    "    counter += 1"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
